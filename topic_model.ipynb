{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_sample = [\"\"\"Hi, I am having trouble with my computer. It is not working.\"\"\"]\n",
    "dialog_sample.append(\"\"\"Hmm.. What's the behavior of your computer?\"\"\")\n",
    "dialog_sample.append(\"\"\"When I was playing a game, it suddenly shut down. Then I tried to turn it on again, but it didn't work.\"\"\")\n",
    "dialog_sample.append(\"\"\"Oh, I see. What's the model of your computer?\"\"\")\n",
    "dialog_sample.append(\"\"\"It's a Dell XPS 15 9570.\"\"\")\n",
    "dialog_sample.append(\"\"\"Hmm.. I see. What's the operating system of your computer?\"\"\")\n",
    "dialog_sample.append(\"\"\"It's Windows 10.\"\"\")\n",
    "dialog_sample.append(\"\"\"Gotya. Please wait a moment while I check the issue.\"\"\")\n",
    "\n",
    "# dialog_sample = ' '.join(dialog_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Extraction\n",
    "\n",
    "LDA is not able to output the exact topic of a document in text format. It can only distinguish different documents for different topics. For example, it can say, in the three documents, document 1 and document 2 have the same topic, but it can't output their topic 'sports'.\n",
    "\n",
    "In details, see https://zhuanlan.zhihu.com/p/29932017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.108*\"issu\" + 0.108*\"check\" + 0.108*\"wait\" + 0.108*\"moment\" + 0.108*\"gotya\" + 0.108*\"window\" + 0.027*\"behavior\" + 0.027*\"model\" + 0.027*\"oper\" + 0.027*\"dell\"\n",
      "Topic: 1 \n",
      "Words: 0.100*\"troubl\" + 0.100*\"have\" + 0.100*\"dell\" + 0.100*\"oper\" + 0.100*\"behavior\" + 0.100*\"model\" + 0.099*\"work\" + 0.025*\"window\" + 0.025*\"gotya\" + 0.025*\"check\"\n",
      "Topic: 2 \n",
      "Words: 0.101*\"work\" + 0.100*\"tri\" + 0.100*\"suddenli\" + 0.100*\"game\" + 0.100*\"shut\" + 0.100*\"play\" + 0.100*\"turn\" + 0.025*\"model\" + 0.025*\"oper\" + 0.025*\"dell\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result\n",
    "\n",
    "processed_docs = [preprocess(sentence) for sentence in dialog_sample]\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 3, id2word = dictionary, passes = 10, workers = 2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Majority Vote on Each Sentence\n",
    "\n",
    "A traditional implementation without using spaCy is shown below. If you want to use the spaCy one, try: https://betterprogramming.pub/extract-keywords-using-spacy-in-python-4a8415478fbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi', 'trouble', 'computer', 'working'], ['Hmm', 'behavior', 'computer'], ['wa', 'playing', 'game', 'suddenly', 'shut', 'tried', 'turn', 'nt', 'work'], ['Oh', 'see', 'model', 'computer'], ['Dell', 'XPS', '15', '9570'], ['Hmm', 'see', 'operating', 'system', 'computer'], ['Windows', '10'], ['Gotya', 'Please', 'wait', 'moment', 'check', 'issue']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('computer', 4)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# we want to extract the entity of each sentence in the dialog, then do a majority vote to get the final entity\n",
    "votes_for_dialog = []\n",
    "for sentence in dialog_sample:\n",
    "    token_list = word_tokenize(sentence)\n",
    "    # remove punctuations\n",
    "    token_list = [re.sub(r'[^\\w\\s]','',token) for token in token_list]\n",
    "    token_list = [token for token in token_list if token != '']\n",
    "    token_list = [lemmatizer.lemmatize(token) for token in token_list]\n",
    "    votes_for_sentence = []\n",
    "    for token in token_list:\n",
    "        # remove stopwords, ignore case\n",
    "        if token.lower() in stopwords.words('english'):\n",
    "            continue   \n",
    "        votes_for_sentence.append(token)\n",
    "    votes_for_dialog.append(votes_for_sentence)\n",
    "\n",
    "print(votes_for_dialog)\n",
    "\n",
    "# do a majority vote\n",
    "from collections import Counter\n",
    "votes = Counter([item for sublist in votes_for_dialog for item in sublist])\n",
    "votes.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepBrick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4388e4eebc4e993b8cb0b7199bea34ffbdc26dc712fa395c44b682c649757ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
